{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f250c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                                                                            #\n",
    "#  Code for the USENIX Security '22 paper:                                   #\n",
    "#  How Machine Learning Is Solving the Binary Function Similarity Problem.   #\n",
    "#                                                                            #\n",
    "#  MIT License                                                               #\n",
    "#                                                                            #\n",
    "#  Copyright (c) 2019-2022 Cisco Talos                                       #\n",
    "#                                                                            #\n",
    "#  Permission is hereby granted, free of charge, to any person obtaining     #\n",
    "#  a copy of this software and associated documentation files (the           #\n",
    "#  \"Software\"), to deal in the Software without restriction, including       #\n",
    "#  without limitation the rights to use, copy, modify, merge, publish,       #\n",
    "#  distribute, sublicense, and/or sell copies of the Software, and to        #\n",
    "#  permit persons to whom the Software is furnished to do so, subject to     #\n",
    "#  the following conditions:                                                 #\n",
    "#                                                                            #\n",
    "#  The above copyright notice and this permission notice shall be            #\n",
    "#  included in all copies or substantial portions of the Software.           #\n",
    "#                                                                            #\n",
    "#  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,           #\n",
    "#  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF        #\n",
    "#  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND                     #\n",
    "#  NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE    #\n",
    "#  LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION    #\n",
    "#  OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION     #\n",
    "#  WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.           #\n",
    "#                                                                            #\n",
    "#  Convert Asm2vec results                                                   #\n",
    "#                                                                            #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerical-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(e1, e2):\n",
    "    return np.dot(e1, e2)\n",
    "\n",
    "def cosine_similarity(e1, e2):\n",
    "    return 1 - cosine(e1, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liquid-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(df_input):\n",
    "    sim_list = list()\n",
    "    for idx, row in tqdm(df_input.iterrows()):\n",
    "\n",
    "        if row['embeddings_1'] is np.nan or \\\n",
    "                row['embeddings_2'] is np.nan:\n",
    "            print(\"[!] Missing value in (idx:{})\".format(idx))\n",
    "            sim_list.append(0)\n",
    "            continue\n",
    "\n",
    "        e1 = np.array([float(x) for x in row['embeddings_1'].split(\";\")])\n",
    "        e2 = np.array([float(x) for x in row['embeddings_2'].split(\";\")])\n",
    "        sim_list.append(cosine_similarity(e1, e2))\n",
    "    return sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lesser-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_similarity(df_pairs, df_asm2vec, is_pos):\n",
    "    df_pairs = df_pairs.merge(df_asm2vec,\n",
    "                              how='left',\n",
    "                              left_on=['idb_path_1', 'fva_1'],\n",
    "                              right_on=['idb_path', 'fva'])\n",
    "    df_pairs.rename(columns={'embeddings': 'embeddings_1'}, inplace=True)\n",
    "\n",
    "    df_pairs = df_pairs.merge(df_asm2vec,\n",
    "                              how='left',\n",
    "                              left_on=['idb_path_2', 'fva_2'],\n",
    "                              right_on=['idb_path', 'fva'])\n",
    "    df_pairs.rename(columns={'embeddings': 'embeddings_2'}, inplace=True)\n",
    "\n",
    "    df_pairs['sim'] = compute_cosine_similarity(df_pairs)\n",
    "\n",
    "    del df_pairs['embeddings_1']\n",
    "    del df_pairs['embeddings_2']\n",
    "\n",
    "    return df_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cddf5",
   "metadata": {},
   "source": [
    "### Process Dataset-1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB1_PATH = \"../../DBs/Dataset-1/pairs/testing/\"\n",
    "\n",
    "for folder in [\n",
    "    'Dataset-1_asm2vec_e3',\n",
    "    'Dataset-1_pvdbow_e3',\n",
    "        'Dataset-1_pvdm_e3']:\n",
    "\n",
    "    embedding_path = os.path.join(\n",
    "        \"../data/raw_results/Asm2vec/\", folder, \"embeddings.csv\")\n",
    "    print(\"[D] Processing {}\".format(embedding_path))\n",
    "    if not os.path.isfile(embedding_path):\n",
    "        print(\"[!] File not found: {}\".format(embedding_path))\n",
    "        continue\n",
    "\n",
    "    df_emb = pd.read_csv(embedding_path)\n",
    "\n",
    "    df_pos = pd.read_csv(os.path.join(DB1_PATH, \"pos_testing_Dataset-1.csv\"), index_col=0)\n",
    "    df_neg = pd.read_csv(os.path.join(DB1_PATH, \"neg_testing_Dataset-1.csv\"), index_col=0)\n",
    "    df_pos_rank = pd.read_csv(os.path.join(DB1_PATH, \"pos_rank_testing_Dataset-1.csv\"), index_col=0)\n",
    "    df_neg_rank = pd.read_csv(os.path.join(DB1_PATH, \"neg_rank_testing_Dataset-1.csv\"), index_col=0)\n",
    "    \n",
    "    df_pos = compute_embedding_similarity(df_pos, df_emb, is_pos=True)\n",
    "    df_neg = compute_embedding_similarity(df_neg, df_emb, is_pos=True)\n",
    "    df_pos_rank = compute_embedding_similarity(df_pos_rank, df_emb, is_pos=True)\n",
    "    df_neg_rank = compute_embedding_similarity(df_neg_rank, df_emb, is_pos=True)\n",
    "\n",
    "    df_pos.to_csv(\"../data/Dataset-1/pos_testing_{}.csv\".format(folder), index=False)\n",
    "    df_neg.to_csv(\"../data/Dataset-1/neg_testing_{}.csv\".format(folder), index=False)\n",
    "    df_pos_rank.to_csv(\"../data/Dataset-1/pos_rank_testing_{}.csv\".format(folder), index=False)\n",
    "    df_neg_rank.to_csv(\"../data/Dataset-1/neg_rank_testing_{}.csv\".format(folder), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ad018",
   "metadata": {},
   "source": [
    "### Process Dataset-2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monthly-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-2_asm2vec_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:12, 12291.55it/s]\n",
      "150000it [00:12, 12296.05it/s]\n",
      "600it [00:00, 12261.66it/s]\n",
      "60000it [00:04, 12310.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-2_pvdbow_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:12, 12035.30it/s]\n",
      "150000it [00:12, 11957.38it/s]\n",
      "600it [00:00, 11958.90it/s]\n",
      "60000it [00:04, 12043.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-2_pvdm_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [00:12, 11913.91it/s]\n",
      "150000it [00:12, 11684.97it/s]\n",
      "600it [00:00, 11644.43it/s]\n",
      "60000it [00:04, 12045.19it/s]\n"
     ]
    }
   ],
   "source": [
    "DB2_PATH = \"../../DBs/Dataset-2/pairs/\"\n",
    "\n",
    "for folder in [\n",
    "    'Dataset-2_asm2vec_e10',\n",
    "    'Dataset-2_pvdbow_e10',\n",
    "        'Dataset-2_pvdm_e10']:\n",
    "\n",
    "    embedding_path = os.path.join(\n",
    "        \"../data/raw_results/Asm2vec/\", folder, \"embeddings.csv\")\n",
    "    print(\"[D] Processing {}\".format(embedding_path))\n",
    "    if not os.path.isfile(embedding_path):\n",
    "        print(\"[!] File not found: {}\".format(embedding_path))\n",
    "        continue\n",
    "\n",
    "    df_emb = pd.read_csv(embedding_path)\n",
    "\n",
    "    df_pos = pd.read_csv(os.path.join(DB2_PATH, \"pos_testing_Dataset-2.csv\"), index_col=0)\n",
    "    df_neg = pd.read_csv(os.path.join(DB2_PATH, \"neg_testing_Dataset-2.csv\"), index_col=0)\n",
    "    df_pos_rank = pd.read_csv(os.path.join(DB2_PATH, \"pos_rank_testing_Dataset-2.csv\"), index_col=0)\n",
    "    df_neg_rank = pd.read_csv(os.path.join(DB2_PATH, \"neg_rank_testing_Dataset-2.csv\"), index_col=0)\n",
    "    \n",
    "    df_pos = compute_embedding_similarity(df_pos, df_emb, is_pos=True)\n",
    "    df_neg = compute_embedding_similarity(df_neg, df_emb, is_pos=True)\n",
    "    df_pos_rank = compute_embedding_similarity(df_pos_rank, df_emb, is_pos=True)\n",
    "    df_neg_rank = compute_embedding_similarity(df_neg_rank, df_emb, is_pos=True)\n",
    "\n",
    "    df_pos.to_csv(\"../data/Dataset-2/pos_testing_{}.csv\".format(folder), index=False)\n",
    "    df_neg.to_csv(\"../data/Dataset-2/neg_testing_{}.csv\".format(folder), index=False)\n",
    "    df_pos_rank.to_csv(\"../data/Dataset-2/pos_rank_testing_{}.csv\".format(folder), index=False)\n",
    "    df_neg_rank.to_csv(\"../data/Dataset-2/neg_rank_testing_{}.csv\".format(folder), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d0b78",
   "metadata": {},
   "source": [
    "### Process Dataset-Vulnerability results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7647b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-Vulnerability_asm2vec_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88700it [00:07, 12208.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-Vulnerability_pvdbow_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88700it [00:07, 12258.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Processing ../data/raw_results/Asm2vec/Dataset-Vulnerability_pvdm_e10/embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88700it [00:07, 12289.16it/s]\n"
     ]
    }
   ],
   "source": [
    "DB2_PATH = \"../../DBs/Dataset-Vulnerability/pairs/\"\n",
    "\n",
    "for folder in [\n",
    "    'Dataset-Vulnerability_asm2vec_e10',\n",
    "    'Dataset-Vulnerability_pvdbow_e10',\n",
    "    'Dataset-Vulnerability_pvdm_e10']:\n",
    "\n",
    "    embedding_path = os.path.join(\n",
    "        \"../data/raw_results/Asm2vec/\", folder, \"embeddings.csv\")\n",
    "    print(\"[D] Processing {}\".format(embedding_path))\n",
    "    if not os.path.isfile(embedding_path):\n",
    "        print(\"[!] File not found: {}\".format(embedding_path))\n",
    "        continue\n",
    "\n",
    "    df_emb = pd.read_csv(embedding_path)\n",
    "\n",
    "    df_testing = pd.read_csv(os.path.join(DB2_PATH, \"pairs_testing_Dataset-Vulnerability.csv\"), index_col=0)\n",
    "    \n",
    "    df_testing = compute_embedding_similarity(df_testing, df_emb, is_pos=True)\n",
    "\n",
    "    df_testing.to_csv(\"../data/Dataset-Vulnerability/testing_{}.csv\".format(folder), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87332de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
