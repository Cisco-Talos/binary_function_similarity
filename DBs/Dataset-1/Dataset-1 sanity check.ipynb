{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f9aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                                                                            #\n",
    "#  Code for the USENIX Security '22 paper:                                   #\n",
    "#  How Machine Learning Is Solving the Binary Function Similarity Problem.   #\n",
    "#                                                                            #\n",
    "#  MIT License                                                               #\n",
    "#                                                                            #\n",
    "#  Copyright (c) 2019-2022 Cisco Talos                                       #\n",
    "#                                                                            #\n",
    "#  Permission is hereby granted, free of charge, to any person obtaining     #\n",
    "#  a copy of this software and associated documentation files (the           #\n",
    "#  \"Software\"), to deal in the Software without restriction, including       #\n",
    "#  without limitation the rights to use, copy, modify, merge, publish,       #\n",
    "#  distribute, sublicense, and/or sell copies of the Software, and to        #\n",
    "#  permit persons to whom the Software is furnished to do so, subject to     #\n",
    "#  the following conditions:                                                 #\n",
    "#                                                                            #\n",
    "#  The above copyright notice and this permission notice shall be            #\n",
    "#  included in all copies or substantial portions of the Software.           #\n",
    "#                                                                            #\n",
    "#  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,           #\n",
    "#  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF        #\n",
    "#  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND                     #\n",
    "#  NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE    #\n",
    "#  LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION    #\n",
    "#  OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION     #\n",
    "#  WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.           #\n",
    "#                                                                            #\n",
    "#  Dataset-1 sanity check                                                    #\n",
    "#                                                                            #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7758f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements\n",
    "# pandas==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdeb60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SELECTED_FUNCS_TRAINING = 256625\n",
    "N_SELECTED_BINARIES_TRAINING = 2978\n",
    "\n",
    "N_SELECTED_FUNCS_VALIDATION = 12736\n",
    "N_SELECTED_BINARIES_VALIDATION = 859\n",
    "\n",
    "N_SELECTED_FUNCS_TESTING = 522003\n",
    "N_SELECTED_BINARIES_TESTING = 919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737a6c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset-1 plots.ipynb        testing_Dataset-1.csv\r\n",
      "Dataset-1 sanity check.ipynb training_Dataset-1.csv\r\n",
      "\u001b[34mfeatures\u001b[m\u001b[m                     validation_Dataset-1.csv\r\n",
      "\u001b[34mpairs\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf0885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_acfg_disasm (__main__.TestDataset1) ... ok\n",
      "test_acfg_features (__main__.TestDataset1) ... ok\n",
      "test_binary_files (__main__.TestDataset1) ... ok\n",
      "test_flowchart_dataset (__main__.TestDataset1) ... ok\n",
      "test_fss (__main__.TestDataset1) ... ok\n",
      "test_pairs_dataset_testing (__main__.TestDataset1) ... ok\n",
      "test_pairs_dataset_validation (__main__.TestDataset1) ... ok\n",
      "test_selected (__main__.TestDataset1) ... ok\n",
      "test_testing_dataset (__main__.TestDataset1) ... ok\n",
      "test_training_dataset (__main__.TestDataset1) ... ok\n",
      "test_validation_dataset (__main__.TestDataset1) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 70.876s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1203da640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestDataset1(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        training_dataset = pd.read_csv(\"training_Dataset-1.csv\", index_col=0)\n",
    "        self.fva_set_training = set([tuple(x) for x in training_dataset[['idb_path', 'fva']].values])\n",
    "        self.idb_set_training = set(training_dataset['idb_path'].values)\n",
    "        \n",
    "        validation_dataset = pd.read_csv(\"validation_Dataset-1.csv\", index_col=0)\n",
    "        self.fva_set_validation = set([tuple(x) for x in validation_dataset[['idb_path', 'fva']].values])\n",
    "        self.idb_set_validation = set(validation_dataset['idb_path'].values)\n",
    "\n",
    "        testing_dataset = pd.read_csv(\"testing_Dataset-1.csv\", index_col=0)\n",
    "        self.fva_set_testing = set([tuple(x) for x in testing_dataset[['idb_path', 'fva']].values])\n",
    "        self.idb_set_testing = set(testing_dataset['idb_path'].values)\n",
    "        \n",
    "    def test_training_dataset(self):\n",
    "        training_dataset = pd.read_csv(\"training_Dataset-1.csv\", index_col=0)\n",
    "\n",
    "        # Test null values\n",
    "        self.assertFalse(training_dataset.isnull().values.any())\n",
    "\n",
    "        # Test number of unique functions\n",
    "        self.assertEqual(training_dataset.shape[0], N_SELECTED_FUNCS_TRAINING)\n",
    "        fva_set_training = set([tuple(x) for x in training_dataset[['idb_path', 'fva']].values])\n",
    "        self.assertEqual(len(fva_set_training), N_SELECTED_FUNCS_TRAINING)\n",
    "\n",
    "        # Test the number of unique binaries\n",
    "        idb_set_training = set(training_dataset['idb_path'].values)\n",
    "        self.assertEqual(len(idb_set_training), N_SELECTED_BINARIES_TRAINING)\n",
    "    \n",
    "    def test_validation_dataset(self):\n",
    "        validation_dataset = pd.read_csv(\"validation_Dataset-1.csv\", index_col=0)\n",
    "        \n",
    "        # Test null values\n",
    "        self.assertFalse(validation_dataset.isnull().values.any())\n",
    "        \n",
    "        # Test number of unique functions\n",
    "        self.assertEqual(validation_dataset.shape[0], N_SELECTED_FUNCS_VALIDATION)\n",
    "        fva_set_validation = set([tuple(x) for x in validation_dataset[['idb_path', 'fva']].values])\n",
    "        self.assertEqual(len(fva_set_validation), N_SELECTED_FUNCS_VALIDATION)\n",
    "        \n",
    "        # Test the number of unique binaries\n",
    "        idb_set_validation = set(validation_dataset['idb_path'].values)\n",
    "        self.assertEqual(len(idb_set_validation), N_SELECTED_BINARIES_VALIDATION)\n",
    "    \n",
    "    def test_testing_dataset(self):\n",
    "        testing_dataset = pd.read_csv(\"testing_Dataset-1.csv\", index_col=0)\n",
    "\n",
    "        # Test null values\n",
    "        self.assertFalse(testing_dataset.isnull().values.any())\n",
    "\n",
    "        # Test number of unique functions\n",
    "        self.assertEqual(testing_dataset.shape[0], N_SELECTED_FUNCS_TESTING)\n",
    "        fva_set_testing = set([tuple(x) for x in testing_dataset[['idb_path', 'fva']].values])\n",
    "        self.assertEqual(len(fva_set_testing), N_SELECTED_FUNCS_TESTING)\n",
    "\n",
    "        # Test the number of unique binaries\n",
    "        idb_set_testing = set(testing_dataset['idb_path'].values)\n",
    "        self.assertEqual(len(idb_set_testing), N_SELECTED_BINARIES_TESTING)\n",
    "        \n",
    "    def test_flowchart_dataset(self):\n",
    "        flowchart_dataset = pd.read_csv(\"features/flowchart_Dataset-1.csv\")\n",
    "\n",
    "        # Test null values\n",
    "        self.assertFalse(flowchart_dataset.isnull().values.any())\n",
    "\n",
    "        # Functions in testing_dataset must a subset of those in flowchart\n",
    "        fc_fva_set = set([tuple(x) for x in flowchart_dataset[['idb_path', 'fva']].values])\n",
    "        self.assertEqual(self.fva_set_training & fc_fva_set, self.fva_set_training)\n",
    "        self.assertEqual(self.fva_set_validation & fc_fva_set, self.fva_set_validation)\n",
    "        self.assertEqual(self.fva_set_testing & fc_fva_set, self.fva_set_testing)\n",
    "    \n",
    "    def test_pairs_dataset_testing(self):\n",
    "        for pair_name in os.listdir(\"pairs/testing/\"):\n",
    "            if not pair_name.endswith(\".csv\"):\n",
    "                continue\n",
    "            pair_path = os.path.join(\"pairs/testing/\", pair_name)\n",
    "\n",
    "            pairs_dataset = pd.read_csv(pair_path, index_col=0)\n",
    "\n",
    "            # Test null values\n",
    "            self.assertFalse(pairs_dataset.isnull().values.any())\n",
    "\n",
    "            # Test pairs size            \n",
    "            dt = dict(pairs_dataset.groupby(\"db_type\").count()['idb_path_1'].items())\n",
    "            if pair_name.startswith(\"pos_rank\"):\n",
    "                self.assertDictEqual(dt, {'XA': 200, 'XC': 200, 'XC+XB': 200, 'XM': 200})\n",
    "            elif pair_name.startswith(\"neg_rank\"):\n",
    "                self.assertDictEqual(dt, {'XA': 20000, 'XC': 20000, 'XC+XB': 20000, 'XM': 20000})\n",
    "            else:\n",
    "                self.assertDictEqual(dt, {'XA': 50000, 'XC': 50000, 'XC+XB': 50000, 'XM': 50000, 'arch': 50000, 'bit': 50000, 'comp': 50000, 'opt': 50000, 'ver': 50000})\n",
    "\n",
    "            # Test overlapping functions\n",
    "            p_fva_set = set([tuple(x) for x in pairs_dataset[['idb_path_1', 'fva_1']].values])\n",
    "            p_fva_set |= set([tuple(x) for x in pairs_dataset[['idb_path_2', 'fva_2']].values])\n",
    "            self.assertEqual(p_fva_set & self.fva_set_testing, p_fva_set)\n",
    "    \n",
    "    def test_pairs_dataset_validation(self):\n",
    "        for pair_name in os.listdir(\"pairs/validation/\"):\n",
    "            if not pair_name.endswith(\".csv\"):\n",
    "                continue\n",
    "            pair_path = os.path.join(\"pairs/validation/\", pair_name)\n",
    "\n",
    "            pairs_dataset = pd.read_csv(pair_path, index_col=0)\n",
    "\n",
    "            # Test null values\n",
    "            self.assertFalse(pairs_dataset.isnull().values.any())\n",
    "\n",
    "            # Test pairs size            \n",
    "            dt = dict(pairs_dataset.groupby(\"db_type\").count()['idb_path_1'].items())\n",
    "            self.assertDictEqual(dt, {'XA': 10000, 'XC': 10000, 'XC+XB': 10000, 'XM': 10000})\n",
    "\n",
    "            # Test overlapping functions\n",
    "            p_fva_set = set([tuple(x) for x in pairs_dataset[['idb_path_1', 'fva_1']].values])\n",
    "            p_fva_set |= set([tuple(x) for x in pairs_dataset[['idb_path_2', 'fva_2']].values])\n",
    "            self.assertEqual(p_fva_set & self.fva_set_validation, p_fva_set)\n",
    "        \n",
    "    def test_selected(self):\n",
    "        with open(\"features/training/selected_training_Dataset-1.json\") as f_in:\n",
    "            selected = json.load(f_in)\n",
    "            \n",
    "            # Test overlapping functions\n",
    "            entries_s = set([(k, hex(v)) for k in selected for v in selected[k]])\n",
    "            self.assertEqual(entries_s & self.fva_set_training, entries_s | self.fva_set_training)\n",
    "        \n",
    "        with open(\"features/validation/selected_validation_Dataset-1.json\") as f_in:\n",
    "            selected = json.load(f_in)\n",
    "            \n",
    "            # Test overlapping functions\n",
    "            entries_s = set([(k, hex(v)) for k in selected for v in selected[k]])\n",
    "            self.assertEqual(entries_s & self.fva_set_validation, entries_s | self.fva_set_validation)\n",
    "        \n",
    "        with open(\"features/testing/selected_testing_Dataset-1.json\") as f_in:\n",
    "            selected = json.load(f_in)\n",
    "            \n",
    "            # Test overlapping functions\n",
    "            entries_s = set([(k, hex(v)) for k in selected for v in selected[k]])\n",
    "            self.assertEqual(entries_s & self.fva_set_testing, entries_s | self.fva_set_testing)\n",
    "\n",
    "    def test_binary_files(self):\n",
    "        a_list = [self.idb_set_training, self.idb_set_validation, self.idb_set_testing]\n",
    "        b_list = [N_SELECTED_BINARIES_TRAINING, N_SELECTED_BINARIES_VALIDATION, N_SELECTED_BINARIES_TESTING]\n",
    "        for bin_list, n_binaries in zip (a_list, b_list):\n",
    "            binary_counter = 0\n",
    "            for path in bin_list:\n",
    "                npath = path.replace(\"IDBs/\", \"../../Binaries/\")\n",
    "                npath = npath.replace(\".i64\", \"\")\n",
    "                if os.path.isfile(npath):\n",
    "                    binary_counter += 1\n",
    "            self.assertEqual(binary_counter, n_binaries)\n",
    "    \n",
    "    def test_acfg_disasm(self):\n",
    "        a_list = [self.idb_set_training, self.idb_set_validation, self.idb_set_testing]\n",
    "        b_list = [N_SELECTED_BINARIES_TRAINING, N_SELECTED_BINARIES_VALIDATION, N_SELECTED_BINARIES_TESTING]\n",
    "        c_list = ['training', 'validation', 'testing']\n",
    "        for bin_list, n_binaries, folder in zip (a_list, b_list, c_list):\n",
    "            j_counter = 0\n",
    "            for path in bin_list:\n",
    "                path = os.path.join(\n",
    "                    \"features/{}/acfg_disasm_Dataset-1_{}\".format(folder, folder),\n",
    "                    os.path.basename(path).replace(\".i64\", \"_acfg_disasm.json\"))\n",
    "                if os.path.isfile(path):\n",
    "                    j_counter += 1\n",
    "            self.assertEqual(j_counter, n_binaries)\n",
    "    \n",
    "    def test_acfg_features(self):\n",
    "        a_list = [self.idb_set_training, self.idb_set_validation, self.idb_set_testing]\n",
    "        b_list = [N_SELECTED_BINARIES_TRAINING, N_SELECTED_BINARIES_VALIDATION, N_SELECTED_BINARIES_TESTING]\n",
    "        c_list = ['training', 'validation', 'testing']\n",
    "        for bin_list, n_binaries, folder in zip (a_list, b_list, c_list):\n",
    "            j_counter = 0\n",
    "            for path in bin_list:\n",
    "                path = os.path.join(\n",
    "                    \"features/{}/acfg_features_Dataset-1_{}\".format(folder, folder),\n",
    "                    os.path.basename(path).replace(\".i64\", \"_acfg_features.json\"))\n",
    "                if os.path.isfile(path):\n",
    "                    j_counter += 1\n",
    "            self.assertEqual(j_counter, n_binaries)\n",
    "    \n",
    "    def test_fss(self):\n",
    "        a_list = [self.idb_set_training, self.idb_set_validation, self.idb_set_testing]\n",
    "        b_list = [N_SELECTED_BINARIES_TRAINING, N_SELECTED_BINARIES_VALIDATION, N_SELECTED_BINARIES_TESTING]\n",
    "        c_list = ['training', 'validation', 'testing']\n",
    "        for bin_list, n_binaries, folder in zip (a_list, b_list, c_list):\n",
    "            j_counter = 0\n",
    "            for path in bin_list:\n",
    "                path = os.path.join(\n",
    "                    \"features/{}/fss_Dataset-1_{}\".format(folder, folder),\n",
    "                    os.path.basename(path).replace(\".i64\", \"_Capstone_True_fss.json\"))\n",
    "                if os.path.isfile(path):\n",
    "                    j_counter += 1\n",
    "            self.assertEqual(j_counter, n_binaries)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
